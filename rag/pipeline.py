# rag/pipeline.py
import logging
from typing import Optional

from langchain.chains import ConversationalRetrievalChain
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory

from .vectorestore import create_fresh_vectorstore
from .config import OPENAI_API_KEY, LLM_MODEL_NAME, TEMPERATURE

# –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –≥–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç
rag_chain: Optional[ConversationalRetrievalChain] = None

def _make_chain(vs) -> ConversationalRetrievalChain:
    """
    –°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—É—é RAG‚Äë—Ü–µ–ø–æ—á–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä—Å—Ç–æ—Ä–∞.
    """
    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        model_name=LLM_MODEL_NAME,
        temperature=TEMPERATURE,
    )
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="answer",
    )
    chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vs.as_retriever(search_kwargs={"k": 5}),
        memory=memory,
        return_source_documents=True,
        output_key="answer",
    )
    return chain

def get_rag_chain() -> ConversationalRetrievalChain:
    """
    –ü—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ —Å–æ–∑–¥–∞—ë—Ç RAG‚Äë—Ü–µ–ø–æ—á–∫—É.
    –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç —É–∂–µ –≥–æ—Ç–æ–≤—É—é.
    """
    global rag_chain
    if rag_chain is None:
        logging.info("üîÑ  –°–æ–∑–¥–∞—ë–º RAG‚Äë—Ü–µ–ø–æ—á–∫—É –≤–ø–µ—Ä–≤—ã–µ‚Ä¶")
        vs = create_fresh_vectorstore()
        rag_chain = _make_chain(vs)
        logging.info("‚úÖ  RAG‚Äë—Ü–µ–ø–æ—á–∫–∞ —Å–æ–∑–¥–∞–Ω–∞")
    return rag_chain

def refresh_chain() -> None:
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏ RAG‚Äë—Ü–µ–ø–æ—á–∫—É.
    –í—ã–∑—ã–≤–∞–π—Ç–µ –µ–≥–æ –ø–æ—Å–ª–µ –ª—é–±—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–∞–Ω–Ω—ã—Ö.
    """
    global rag_chain
    logging.info("üîÑ  –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –∏ RAG‚Äë—Ü–µ–ø–æ—á–∫—É‚Ä¶")
    vs = create_fresh_vectorstore()
    rag_chain = _make_chain(vs)
    logging.info("‚úÖ  RAG‚Äë—Ü–µ–ø–æ—á–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞")

def get_answer(question: str, source: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å, —Ñ–∏–ª—å—Ç—Ä—É—è –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º source.
    """
    chain = get_rag_chain()
    # –æ–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫
    chain.retriever.search_kwargs["filter"] = {"source": source}
    result = chain({"question": question})
    docs = result.get("source_documents") or []
    return result["answer"] if docs else "–ù–µ –Ω–∞—à–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É."